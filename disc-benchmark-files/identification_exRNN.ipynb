{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917567a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['text.usetex'] = False\n",
    "import numpy as np\n",
    "\n",
    "# register acceleration devices\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load Benchmark Data\n",
    "\n",
    "out = np.load('training-val-test-data.npz')\n",
    "th_data = out['th'] #th[0],th[1],th[2],th[3],...\n",
    "u_data = out['u'] #u[0],u[1],u[2],u[3],...\n",
    "\n",
    "from sklearn import model_selection\n",
    "u_train, u_val, y_train, y_val= model_selection.train_test_split(u_data, th_data, shuffle=False, test_size=0.3,random_state=42)\n",
    "\n",
    "def make_OE_data(udata, ydata, nf=100):\n",
    "    U = [] \n",
    "    Y = [] \n",
    "    for k in range(nf,len(udata)+1):\n",
    "        U.append(udata[k-nf:k]) #a)\n",
    "        Y.append(ydata[k-nf:k]) #a)\n",
    "    return np.array(U), np.array(Y)\n",
    "\n",
    "nfuture = 30\n",
    "convert = lambda x: [torch.tensor(xi,dtype=torch.float64,device=device) for xi in x]\n",
    "Utrain, Ytrain = convert(make_OE_data(u_train, y_train, nf=nfuture))\n",
    "Uval,   Yval   = convert(make_OE_data(u_val,   y_val,   nf=len(u_val))) #uses the whole data set for OE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d306e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from EX3\n",
    "class simple_RNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(simple_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        net = lambda n_in,n_out: nn.Sequential(nn.Linear(n_in,40), \\\n",
    "                                               nn.Sigmoid(), \\\n",
    "                                               nn.Linear(40,n_out)).double() #new short hand\n",
    "        self.h2h = net(self.input_size + hidden_size, self.hidden_size) #b=)\n",
    "        self.h2o = net(self.input_size + hidden_size, self.output_size) #b=)\n",
    "                                                                        #[:,0] should be called after use of h2o\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #input.shape == (N_batch, N_time)\n",
    "        hidden = torch.zeros(inputs.shape[0], self.hidden_size, dtype=torch.float64) #c)\n",
    "        outputs = [] #c)\n",
    "        for i in range(inputs.shape[1]): #c)\n",
    "            u = inputs[:,i] #shape = (N_batch,) #c)\n",
    "            combined = torch.cat((hidden, u[:,None]), dim=1) #c) #shape = (N_batch,hidden_size+1)\n",
    "            outputs.append(self.h2o(combined)[:,0]) #c)\n",
    "            hidden = self.h2h(combined) #c)\n",
    "        return torch.stack(outputs,dim=1) #c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eda5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, Validation NRMS=42.53%, Train NRMS=38.80%\n",
      "epoch=1, Validation NRMS=40.58%, Train NRMS=37.25%\n",
      "epoch=2, Validation NRMS=28.15%, Train NRMS=31.10%\n",
      "epoch=3, Validation NRMS=27.85%, Train NRMS=30.66%\n",
      "epoch=4, Validation NRMS=25.05%, Train NRMS=30.48%\n",
      "epoch=5, Validation NRMS=26.36%, Train NRMS=29.78%\n",
      "epoch=6, Validation NRMS=27.43%, Train NRMS=30.28%\n",
      "epoch=7, Validation NRMS=27.12%, Train NRMS=29.86%\n",
      "epoch=8, Validation NRMS=27.90%, Train NRMS=30.19%\n",
      "epoch=9, Validation NRMS=27.87%, Train NRMS=29.78%\n",
      "epoch=10, Validation NRMS=30.64%, Train NRMS=29.81%\n",
      "epoch=11, Validation NRMS=29.47%, Train NRMS=30.09%\n",
      "epoch=12, Validation NRMS=24.88%, Train NRMS=29.70%\n",
      "epoch=13, Validation NRMS=27.70%, Train NRMS=29.80%\n",
      "epoch=14, Validation NRMS=27.69%, Train NRMS=29.84%\n",
      "epoch=15, Validation NRMS=28.59%, Train NRMS=29.75%\n",
      "epoch=16, Validation NRMS=31.84%, Train NRMS=29.87%\n",
      "epoch=17, Validation NRMS=28.77%, Train NRMS=29.83%\n",
      "epoch=18, Validation NRMS=27.25%, Train NRMS=29.89%\n",
      "epoch=19, Validation NRMS=32.06%, Train NRMS=29.69%\n",
      "epoch=20, Validation NRMS=26.33%, Train NRMS=29.77%\n",
      "epoch=21, Validation NRMS=27.19%, Train NRMS=29.28%\n",
      "epoch=22, Validation NRMS=28.47%, Train NRMS=29.24%\n",
      "epoch=23, Validation NRMS=23.69%, Train NRMS=29.48%\n",
      "epoch=24, Validation NRMS=24.95%, Train NRMS=28.97%\n",
      "epoch=25, Validation NRMS=23.07%, Train NRMS=28.84%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m Uin \u001b[38;5;241m=\u001b[39m Utrain[ids_now] \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m Y_real \u001b[38;5;241m=\u001b[39m Ytrain[ids_now] \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m Y_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(inputs\u001b[38;5;241m=\u001b[39mUin) \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m residual \u001b[38;5;241m=\u001b[39m Y_real \u001b[38;5;241m-\u001b[39m Y_predict \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m Loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(residual[:,n_burn:]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#d)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:173\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataParallel.forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids:\n\u001b[1;32m--> 173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbuffers()):\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj:\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m, in \u001b[0;36msimple_RNN.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     21\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((hidden, u[:,\u001b[38;5;28;01mNone\u001b[39;00m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#c) #shape = (N_batch,hidden_size+1)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2o(combined)[:,\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m#c)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h(combined) \u001b[38;5;66;03m#c)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(outputs,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Kai\\anaconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "n_burn = 10\n",
    "batch_size = 64\n",
    "\n",
    "model = simple_RNN(hidden_size=15) #d=)\n",
    "model = nn.DataParallel(model) # Wrap the model with DataParallel\n",
    "model = model.to(device=device) # Move the model to the GPU\n",
    "optimizer = torch.optim.Adam(model.parameters()) #d=)\n",
    "\n",
    "\n",
    "ids = np.arange(len(Utrain),dtype=int) \n",
    "for epoch in range(50):\n",
    "    np.random.shuffle(ids) #inspace shuffle of the ids of the training set to select a random subset \n",
    "    for i in range(0,len(Utrain),batch_size):\n",
    "        ids_now = ids[i:i+batch_size] #the ids of the current batch\n",
    "        Uin = Utrain[ids_now] #d)\n",
    "        Y_real = Ytrain[ids_now] #d)\n",
    "\n",
    "        Y_predict = model.forward(inputs=Uin) #d)\n",
    "        residual = Y_real - Y_predict #d)\n",
    "        Loss = torch.mean(residual[:,n_burn:]**2) #d)\n",
    "        \n",
    "        optimizer.zero_grad()  #d)\n",
    "        Loss.backward()  #d)\n",
    "        optimizer.step()  #d)\n",
    "    \n",
    "    with torch.no_grad(): #monitor\n",
    "        Loss_val = torch.mean((model(inputs=Uval)[:,n_burn:] - Yval[:,n_burn:])**2)**0.5\n",
    "        Loss_train = torch.mean((model(inputs=Utrain)[:,n_burn:] - Ytrain[:,n_burn:])**2)**0.5\n",
    "        print(f'epoch={epoch}, Validation NRMS={Loss_val.item():.2%}, Train NRMS={Loss_train.item():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d536e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(Yval[0])\n",
    "    plt.plot(model(inputs=Uval)[0],'--')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('y')\n",
    "    plt.xlim(0,250)\n",
    "    plt.legend(['real','predicted'])\n",
    "    plt.show()\n",
    "    plt.plot(np.mean((Ytrain-model(inputs=Utrain)).numpy()**2,axis=0)**0.5) #average over the error in batch\n",
    "    plt.title('batch averaged time-dependent error')\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('i')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
